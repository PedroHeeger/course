# Imersão Docker e Kubernetes 1   <img src="../curso_116/0-aux/logo_course.png" alt="curso_116" width="auto" height="45">

### Repository: [course](../../../../)
### Platform: <a href="../../">fabricio_veronez   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/plataforma/fabricio_veronez.png" alt="fabricio_veronez" width="auto" height="25"></a>
### Software/Subject: <a href="../">devops   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/content/devops.png" alt="devops" width="auto" height="25"></a>
### Course: <a href="./">curso_116 (Imersão Docker e Kubernetes 1)   <img src="../curso_116/0-aux/logo_course.png" alt="curso_116" width="auto" height="25"></a>

---

### Theme:
- DevOps

### Used Tools:
- Operating System (OS): 
  - Linux   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linux/linux-original.svg" alt="linux" width="auto" height="25">
  - Windows 11   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/windows11.png" alt="windows11" width="auto" height="25">
- Linux Distribution: 
  - Ubuntu   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/ubuntu/ubuntu-plain.svg" alt="ubuntu" width="auto" height="25">
- Cloud:
  - Amazon Web Services (AWS)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/amazonwebservices/amazonwebservices-original.svg" alt="aws" width="auto" height="25">
- Cloud Services:
  - Amazon Elastic Compute Cloud (EC2)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_ec2.svg" alt="aws_ec2" width="auto" height="25">
  - Amazon Elastic Container Registry (ECR)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_ecr.svg" alt="aws_ecr" width="auto" height="25">
  - Google Drive <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/google_drive.png" alt="google_drive" width="auto" height="25">
- Containerization: 
  - Docker   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/docker/docker-original.svg" alt="docker" width="auto" height="25">
- Cluster Management Software:
  - Kubernetes   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/kubernetes/kubernetes-plain.svg" alt="kubernetes" width="auto" height="25">
  - K3D   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/kubernetes_k3d.png" alt="kubernetes_k3d" width="auto" height="25">
- Language:
  - HTML   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/html5/html5-original.svg" alt="html" width="auto" height="25">
  - Markdown   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/markdown/markdown-original.svg" alt="markdown" width="auto" height="25">
  - Node.js   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/nodejs/nodejs-original.svg" alt="nodejs" width="auto" height="25">
  - YAML   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/yaml.png" alt="yaml" width="auto" height="25">
- Integrated Development Environment (IDE) and Text Editor:
  - Nano   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/nano.png" alt="nano" width="auto" height="25">
  - Visual Studio Code (VS Code)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vscode/vscode-original.svg" alt="vscode" width="auto" height="25">
- Versioning: 
  - Git   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" alt="git" width="auto" height="25">
- Repository:
  - Docker Hub   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/docker_hub.png" alt="docker_hub" width="auto" height="25">
  - Docker Registry   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/docker_registry.png" alt="docker_registry" width="auto" height="25">
  - GitHub   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" alt="github" width="auto" height="25">
- Command Line Interpreter (CLI):
  - AWS Command Line Interface (CLI)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_cli.svg" alt="aws_cli" width="auto" height="25">
  - Bash e Sh   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/bash/bash-original.svg" alt="bash_sh" width="auto" height="25">
  - Windows PowerShell   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/windows_power_shell.png" alt="windows_power_shell" width="auto" height="25">
- Server and Databases:
  - Nginx   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/nginx/nginx-original.svg" alt="nginx" width="auto" height="25">
- Tools:
  - Advanced Package Tool (Apt)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/apt.png" alt="apt" width="auto" height="25">
  - Advanced Package Tool (Apt-Get)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/apt-get.jpg" alt="apt-get" width="auto" height="25">
  - Curl   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/curl.png" alt="curl" width="auto" height="25">
  - Node Package Manager (npm)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/npm/npm-original-wordmark.svg" alt="npm" width="auto" height="25">
  - Unrar   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/unrar.png" alt="unrar" width="auto" height="25">
  - Wget   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/wget.webp" alt="wget" width="auto" height="25">
  
---

<a name="item0"><h3>Course Strcuture:</h3></a>
1. <a href="#item01">Aula 1 - Fundamentos e primeiros passos com Docker</a><br>
2. <a href="#item02">Aula 2 - Imagem Docker e sua aplicação 100% em containers com Docker Compose</a><br>
3. <a href="#item03">Aula 3 - Kubernetes: deploy eficiente das aplicações + Oportunidade de se tornar Expert</a><br>

---

### Objective:
O objetivo desse projeto prático foi introduzir algumas duas das principais ferramentas da área de **DevOps**, que são os softwares **Docker** e **Kubernetes**. 


Neste projeto foi desenvolvido uma aplicação web de um microblog (portal de notícias) escrito em **Node.js** que tem como persistência dos dados no banco **PostgreSQL**. Também foi desenvolvido um pipeline de entrega e integração contínua deste projeto utilizando os softwares **GitHub Actions**, **Kubernetes** como ambiente de execução da aplicação e o **Docker** como tecnologia para empacotar a imagem de container para rodar essa aplicação.

### Structure:
A estrutura do projeto (Imagem 01) é formada por:
- A pasta `automation` com os arquivos de scripts em **PowerShell** de automação (`criacao`, `exclusao` e `variaveis`) .
- Duas sub-pastas (`resources` e `secrets`) dentro da pasta `automation`. A primeira com recursos utilizados nesse projeto, seperados por sub-pastas, como arquivos de script em **Bash**, arquivos de manifesto **YAML**, arquivos **Dockerfile**, entre outros. Já a segunda com sub-pastas e arquivos de configuração do usuário da **AWS CLI** e do **Docker Hub**, além do arquivo par de chaves `.pem` para acesso remoto, sendo esta pasta não versionada para o **GitHub** por ter dados sensíveis.
- A pasta do repositório do projeto do **GitHub** do professor, com os projetos da aula 1 e da aula 2, utilizado também na aula 3, 4 e 5.
- A pasta `0-aux`, pasta auxiliar com imagens utilizadas na construção desse arquivo de README. 

<div align="Center"><figure>
    <img src="./0-aux/img01.png" alt="img01"><br>
    <figcaption>Imagem 01.</figcaption>
</figure></div><br>

### Development:

Para desenvolvimento deste curso foi instânciada uma maquina no serviço **Amazon Elastic Compute Cloud (EC2)**


<a name="item01"><h4>Aula 1 - Fundamentos e primeiros passos com Docker</h4></a>[Back to summary](#item0)

Nesta primeira aula do curso, foi realizado uma introdução sobre o software **Docker**, explicando suas vantagens, as tecnologias principais que permitem trabalhar com essa ferramenta, os conceitos de *container* e *imagem*, a arquitetura do **Docker**, as vantagens de utilizá-lo e como está o mercado em relação ao **Docker**. Também foi iniciado uma demonstração de como utilizá-lo, apresentando comandos básicos.

O mercado está cada vez mais competitivo, entregas mais rápidas e com qualidade são uma necessidade, a adoção da arquitetura de microsserviços se tornou um requisito, diversas tecnologias estão sendo utilizadas no mesmo proejto, as empresas cada vez mais estão implementando soluções de DevOps e Cloud. Por conta disso tudo, o uso de containers se tornou um padrão de mercado e para trabalhar com containers, **Docker** e **Kubernetes** são as ferramentas mais adotadas atualmente. Um profissional que domina o **Docker**, consegue ter mais velocidade e mais independência na hora de desenvolver, tem mais facilidade em trabalhar com tecnologias complexas, consegue participar de projetos mais desafiadores e, por consequência, consegue as melhores oportunidades.

A utilização do **Docker** tem como vantagens: melhorar o aproveitamento de recurso da maquina, ter velocidade pra desenvolver e executar aplicações, simplificaçar o deploy, ter portabilidade entre ambientes e similaridade entre ambiente dev e de produção e garantir a idempotência, que é garantir que sempre que for executado um container, ele terá o mesmo comportamento, não importa em qual ambiente esteja sendo executado desde que esse ambiente execute containers.

O **Linux** é quem tem a tecnologia, os recursos no kernel para poder trabalhar com containers. As três principais tecnologias para se trabalhar com containers são: *Namescpaces*, *Cgroup* e *Overlay File System (OverlayFS)*. O *Namespace* é a tecnologia do kernel que possibilita executar processos dentro de processos no **Linux** e dessa forma é que se consegue criar o isolamento de processos. O *Cgroups* entra para limitar a quantidade de recursos para cada processo, então é possível limitar cpu, limitar memória, contribuindo para o isolamento de processos. Já o *Overlay File System* é uma tecnologia que faz com que consiga juntar duas camadas de arquivos de file system, ou seja, pegar dois diretórios com suas estruturas de arquivos dentro deles e uní-los. Essa tecnologia é utilizada na hora de construir imagens de container **Docker**.

A *imagem* é um objeto do **Docker** quer serve de template para criação dos containers. Então a partir de uma única imagem é possível criar vários containers. Nela vai ser colocado tudo que é necessário para criar e executar a aplicação. A imagem, nada mais é, que um conjunto de arquivos criando um File System (Sistema de arquivos). Os *containers* por sua vez, são instâncias das imagens. Eles são objetos efêmeros, que após terem cumprido seu papel pode ser removidos.

Com relação a arquitetura do **Docker**, o primeiro elemento e o principal é o *Docker Daemon*. No *Docker Daemon*, é onde é executado e gerenciado todos os objetos do **Docker** (*imagens*, *containers* e *networks*), todos os componentes do **Docker** vão está dentro do *Docker Daemon* e é nele que vou executar e gerenciar os meus containers. Mas para trabalhar com o *Docker Daemon*, tem que ser utilizado o *Docker Client*. O *Docker Client* é responsável por enviar as instruções e fazer a comunicação do usuário com o *Docker Daemon*. Então toda vez que um comando é executado, o *Docker Client* está sendo utilizado para comunicar com o *Docker Daemon*. Muitas vezes, é possível ter instalado o *Docker Daemon* e o *Docker Client* no mesmo ambiente, no que é chamado de *Docker Host* que é a maquina responsável por hospedar e executar o *Docker Daemon*, normalmente tem-se os dois no *Docker Host*. Mas existe a possibilidade de ter o *Docker Client* em uma maquina se comunicando com o *Docker Daemon* que está em outra maquina remota que está em um datacenter em um ambiente de cloud.

Agora, as imagens que vão ser utilizadas como base para criar os containers, elas precisam estar em algum lugar. É ai que entra o *Docker Registry*, o *Docker Registry* é componente do **Docker** utilizado para armazenar as imagens. Junto com o conceito do *Docker Registry*, tem o **Docker Hub** que é o *Docker Registry* oficial do **Docker**, o principal serviço de *Docker Registry* hoje do mercado que pertence a **Docker**. Ele não é o único, existem diversos outros serviços, inclusive cada Cloud Provider tem o seu serviço de Docker ou Container Registry, como ECR na **AWS** ou o ACR na **Azure**. Inclusive, é possível utilizar ferramentas como o **Harbor** para criar seu próprio Registry no seu ambiente de datacenter.

A demonstração da utilização do **Docker** iniciou com o comando `docker container run hello-world` para baixar e executar um container de exemplo que exibiu a mensagem `hello-world` e depois se encerrou. Com o parâmetro `--name meucontainer1` foi possível executá-lo novamente dando um nome para o container. Com o comando `docker ls` foi listado todos os containers em execução, porém como esses dois criados já tinham sidos encerrados, pois depois que eles exibiram a mensagem eles se encerraram, nenhum container foi exibido. Para listar todos os containers tanto os ativos e os inativos foi acrescentado o parâmetro `-a (--all)`. Para remover os containers inativos utilizou-se o comando `docker rm` com o ID ou nome do container. Quando utilizado com o ID não foi necessário por o ID todo, se não houvesee IDs com digitos inicias iguais, bastava por os dois primeiros IDs que ele identificava e deletava. Caso tivesse containers com IDs com dois dígitos iguais, só era acrescentar mais um dígito até que eles se diferenciassem. Com o comando `docker container --name meucontainer2 run --rm` e a imagem `hello-world` foi construído um container auto-destrutivo, no qual após ele terminasse a execução, ao invés de ficar encerrado, ele era removido.

Dando sequencia, com o comando `docker container run --name container2 -it ubuntu /bin/bash` era criado um container nomeado e com a imagem do **Linux Ubuntu**. O parâmetro `-i (--interactive)` mantinha o o stdin aberto para que fosse possível interagir com o processo executado no container. O *Standard Input (stdin)* é o canal de entrada padrão, sendo uma das três "streams" padrão associadas a um processo em sistemas operacionais Unix-like (como o **Linux**), juntamente com *stdout (saída padrão)* e *stderr (saída de erro padrão)*. Ou seja, com o stdin pôde ser fornecido dados de entrada para o processo dentro do container. Já o parâmetro `-t (--tty)` alocava um interface de terminal, pseudo-TTY (Terminal Teletype), dentro do ambiente do container para que fosse possível enviar e receber sinais de controle para os processos do container. A opção `/bin/bash` foi apenas um comando **Linux** sendo executado, que neste caso, era o caminho até o binário do **Bash**, ou simplesmente o link simbólico `bash`, para iniciar um shell bash. Com o pseudo-terminal alocado, foi possível interagir com os processos desse container que era o **Linux Ubuntu**. Com comando `cat /ect/os-release` foi visualizada as informações do sistema operacional que esse container utilizava. Já com o comando `apt-get update -y` e `apt-get install -y curl` foi atualizado os pacotes do sistema e baixado o software **Curl**. Com o **Curl** foi executado `curl -IL www.google.com` para verificar se o acesso ao site funcionava. Após isso, foi cancelado o processo em execução no terminal local, para voltar ao ambiente local e encerrar o pseudo-terminal do ambiente de container criado.

Com o comando `docker container run -it alpine /bin/bash` foi desenvolvido um outro container que utilizava a imagem do **Linux Alpine** que é uma imagem **Linux** bem mais leve que as outras distruibuições. Também foi alocado o tty e permitido a interatividade, executando novamente um shell bash. Em seguida, foi encerrado o processo e voltado para o terminal local. Com o comando `docker container ls -aq` era listado apenas os IDs de todos os containers (ativos e inativos). O parâmetro `-q (--quiet)` exibiu apenas os IDs dos containers. Com uma combinação de dois comandos `docker container rm $(docker container ls -aq)` foi listado todos os IDs de todos os containers (ativos e inativos) e executado a exclusão deles.

Agora, com o comando `docker container run --name meucontainer2 nginx` foi criado um novo container com imagem do servidor web **Nginx**, porém esse processo estava sendo executado em primeiro plano do terminal, o que deixa o terminal preso. Para liberar o terminal, teve que utilizar o parâmetro `-d (--detach)` para enviar o terminal para segundo plano ou background. Assim, o container continuava em execução (ativo) e o terminal local estava livre para executar novos comandos. Com o comando `docker logs` e o nome ou ID do container foi possível visualizar os logs do container especificado. Já para executar um comando no container pelo terminal local utilizou-se `docker container exec`, nome ou ID do container e o comando que quisesse executar, no caso foi o `ls`. Caso fosse necessário permitir a interatividade e alocar uma tty no ambiente de container com ele em execução foi com o comando `docker container exec -it meucontainer2 /bin/bash`, iniciando o shell bash.


`docker container run -d -p 8080:80 nginx`




<a name="item02"><h4>Aula 2 - Imagem Docker e sua aplicação 100% em containers com Docker Compose</h4></a>[Back to summary](#item0)







<a name="item03"><h4>Aula 3 - Kubernetes: deploy eficiente das aplicações + Oportunidade de se tornar Expert</h4></a>[Back to summary](#item0)

