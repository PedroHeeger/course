# DevOps   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/content/devops.png" alt="devops" width="auto" height="45">

### Repository: [course](../../../../)
### Platform: <a href="../../">fabricio_veronez   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/plataforma/fabricio_veronez.png" alt="fabricio_veronez" width="auto" height="25"></a>
### Software/Subject: <a href="../">devops   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/content/devops.png" alt="devops" width="auto" height="25"></a>
### Course: <a href="./">curso_081 (Imersão DevOps & Cloud)   <img src="./curso_081/0-aux/logo_course.png" alt="curso_081" width="auto" height="25"></a>

#### <a href="">Certificate</a>

---

### Theme:
- Cloud Computing
- DevOps

### Used Tools:
- Operating System (OS): 
  - Linux   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/linux/linux-original.svg" alt="linux" width="auto" height="25">
  - Windows 11   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/windows11.png" alt="windows11" width="auto" height="25">
- Linux Distribution: 
  - Ubuntu   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/ubuntu/ubuntu-plain.svg" alt="ubuntu" width="auto" height="25">
- Virtualization: 
  - Docker   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/docker/docker-original.svg" alt="docker" width="auto" height="25">
- Cloud:
  - Amazon Web Services (AWS)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/amazonwebservices/amazonwebservices-original.svg" alt="aws" width="auto" height="25">
- Cloud Services:
  - Amazon Elastic Compute Cloud (EC2)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_ec2.svg" alt="aws_ec2" width="auto" height="25">
  - Google Drive <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/google_drive.png" alt="google_drive" width="auto" height="25">
- Cluster Management Software:
  - Kubernetes   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/kubernetes/kubernetes-plain.svg" alt="kubernetes" width="auto" height="25">
  - K3D   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/kubernetes_k3d.png" alt="kubernetes_k3d" width="auto" height="25">
- Configuration Management (CM):
  - Terraform   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/terraform/terraform-original.svg" alt="terraform" width="auto" height="25">
- Language:
  - HTML   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/html5/html5-original.svg" alt="html" width="auto" height="25">
  - Markdown   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/markdown/markdown-original.svg" alt="markdown" width="auto" height="25">
- BI Tool:
  - Grafana   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/grafana/grafana-original.svg" alt="grafana" width="auto" height="25">
- Integrated Development Environment (IDE) and Text Editor:
  - Visual Studio Code (VS Code)   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/vscode/vscode-original.svg" alt="vscode" width="auto" height="25">
- Versioning: 
  - Git   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/git/git-original.svg" alt="git" width="auto" height="25">
- Repository:
  - Docker Hub   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/docker_hub.png" alt="docker_hub" width="auto" height="25">
  - Docker Registry   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/docker_registry.png" alt="docker_registry" width="auto" height="25">
  - GitHub   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg" alt="github" width="auto" height="25">
  - Terraform Registry   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/terraform/terraform-original.svg" alt="terraform_registry" width="auto" height="25">
- Command Line Interpreter (CLI):
  - AWS Command Line Interface (CLI)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/cloud/aws_cli.svg" alt="aws_cli" width="auto" height="25">
  - Azure CLI   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/azure/azure-original.svg" alt="azure_cli" width="auto" height="25">
  - Bash e Sh   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/bash/bash-original.svg" alt="bash_sh" width="auto" height="25">
  - Oh My Zshell (Oh My ZSh)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/oh_my_zshell.png" alt="oh_my_zshell" width="auto" height="25">
  - Systemctl   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/systemctl.png" alt="systemctl" width="auto" height="25">
  - Windows PowerShell   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/windows_power_shell.png" alt="windows_power_shell" width="auto" height="25">
  - ZShell   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/zshell.png" alt="zshell" width="auto" height="25">
- Server and Databases:
  - Apache HTTP Server (httpd)   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/apache_http_server.png" alt="apache_httpd" width="auto" height="25">
  - Prometheus   <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/prometheus/prometheus-original.svg" alt="prometheus" width="auto" height="25">
- Workflow Management System (WFMS):
  - GitHub Actions   <img src="https://github.com/PedroHeeger/main/blob/main/0-aux/logos/software/github_actions.png" alt="github_actions" width="auto" height="25">
  
---

<a name="item0"><h3>Course Strcuture:</h3></a>
1. <a href="#item01">Aula 1 - Revolução Digital com DevOps e Cloud</a><br>
2. <a href="#item02">Aula 2 - Kubernetes do zero ao deploy</a><br>
3. <a href="#item03">Aula 3 - AWS: Potencialize sua aplicação com o poder da Cloud Computing</a><br>
4. <a href="#item04">Aula 4 - Github Actions - Eficiência em entregas automatizadas</a><br>
5. <a href="#item05">Class 05</a><br>

---

### Objective:
O objetivo desse projeto prático foi introduzir algumas das principais ferramentas da área de **DevOps**, que são elas: **Docker**, **Kubernetes**, **AWS**, **GitHub Actions** e **Terraform**. Neste projeto foi desenvolvido uma aplicação web de um microblog (portal de notícias) escrito em **Node.js** que tem como persistência da base de dados no banco **PostgreSQL**. Também foi desenvolvido um pipeline de entrega e integração contínua deste projeto utilizando os softwares **GitHub Actions**, **Kubernetes** como ambiente de execução da aplicação, o **Docker** como tecnologia para empacotar a imagem de container para rodar essa aplicação, e o monitoramento dessa aplicação com o **Grafana** e o **Prometheus**.

### Structure:
A estrutura (Imagem 01) do projeto é formada por:
- Dois arquivos em **Excel** um para cada aula, sendo as aulas 2 e 3 resolvidas no mesmo arquivo. 
- Uma pasta com as imagens dos ícones inseridos no report. 
- Duas pastas, uma contendo três arquivos de base de dados em **Excel**, um para cada ano (2021, 2022, 2023), e a outra contendo, também em um arquivo de **Excel**, a base de dados só do mês de Julho/2023 para ser inserida posteriormente. 
- A pasta **0-aux**, pasta auxiliar com imagens utilizadas na construção desse arquivo de README. 
- Obs.: A logomarca do curso foi criada apenas para fins didáticos com uso do site de inteligência artificial **Looka**.

<div align="Center"><figure>
    <img src="./0-aux/img01.PNG" alt="img01"><br>
    <figcaption>Imagem 01.</figcaption>
</figure></div><br>

### Development:
Este projeto foi desenvolvido em cinco aulas, além de conter quatro lives e três desafios. As etapas do projeto estão listadas abaixo.

- Empacotar a aplicação em imagens Docker para executar em containers.
- Rodar a aplicação em ambiente Kubernetes local usando K3D e ambiente de nuvem com AWS.
- Automatizar a entrega das aplicações usando pipeline CI/CD com GitHub Actions.
- Utilizar infraestrutura como código para criar a infraestrutura pra conseguir agilidade, reaproveitamento e confiabilidade.
- Monitorar a aplicação e a infraestrutura para saber o que está acontencendo e se antecipar aos problemas.

<a name="item01"><h4>Aula 1 - Revolução Digital com DevOps e Cloud</h4></a>[Back to summary](#item0)

Na primeira aula desse curso, foi realizada uma introdução sobre o software **Docker**, mostrando alguns comandos básicos desta ferramenta. Para execução do projeto, foi decidido por mim que tudo seria executado na cloud da **AWS** com o objetivo de evitar realizar instalações na maquina física, utilizando o **AWS CLI** no **PowerShell**. Portanto, foi construída e configurada uma maquina virtual **Linux Ubuntu** no serviço **Amazon EC2** da cloud para servir como ambiente de execução, onde seriam feitas as instalações dos programas utilizados e o download dos arquivos do projeto. Todo o processo de configuração desse ambiente foi realizado de forma automatizada através dos três arquivos seguintes de **PowerShell**: [criacao](./automation/criacao.ps1), [exclusao](./automation/exclusao.ps1) e [variaveis](./automation/variaveis.ps1), sendo todos eles armazenados no diretório [automation](./automation/). Este diretório ainda conteve duas sub-pastas, a primeira ([resources](./automation/resources/)), para armazenar os arquivos de recursos necessários, que neste caso, armazenou o arquivo de script em **Bash** [ec2Script.sh](./automation/resources/ec2Script.sh). A outra sub-pasta de nome [secrets](./automation/secrets) continha as credenciais para login do usuário na **AWS CLI**, no **Docker Hub** e o arquivo par de chaves `.pem` gerado para realização de acesso remoto na maquina virtual instanciada na cloud da **AWS**.

No script de criação, todo comando executado foi precedido por comandos de verificação determinando se o serviço ou recurso já havia sido criado através estruturas de condicionais `if else`. Caso o resultado fosse que o elemento já tinha sido criado, o nome dele era listado, além de informações necessárias que também eram exibidas. Já se não houvesse sido criado, era listado o antes e o depois do comando de criação para evidenciar a construção do serviço. Nesta segunda situação, também era listada informações adicionais quando necessário.

O script iniciou com a execução de um par de chaves na cloud da **AWS**, onde as informações foram também armazenadas em um arquivo formato `.pem` dentro da sub-pasta `secrets`, para utilização durante acesso remoto a maquina. Em seguida, foi instanciada a maquina virtual no serviço **EC2** que funcionaria como ambiente de execução, indicando um arquivo de script **Bash** ([ec2Script.sh](./automation/resources/ec2Script.sh)) que seria responsável por realizar as instalações dos softwares e execução dos comandos do projeto. Após isso, uma regra foi adicionada ao grupo de segurança padrão da VPC padrão, ambos utilizados na maquina virtual instanciada. Esta regra consistiu na liberação da porta `8080` do protocolo `TCP` para todas as faixas de IP, para que posteriormente fosse possível acessar a aplicação por um navegador da web na maquina física.

Dando seguimente, foi aguardado um cerca de 200 segundos para que uma parte do script em **Bash** fosse executada, alguns softwares fossem baixados e também que fosse feito o clone da pasta do projeto do **GitHub**, pois alguns arquivos que seriam transferidos iriam para sub-pastas da pasta do projeto. Em seguida foi exibido o endereço para acesso a aplicação que era o IP público da maquina virtual concatenado com o número da porta, que no caso foi a `8080`. Este número de IP passou por um processo de conversão de caracteres para trocar o ponto que separava os números do IP para um traço e então o comando para acesso remoto a maquina era exibido na tela de modo que só era necessário copiar, colar e executar em um shell, que no caso foi utilizado no **PowerShell** da maquina físca. 

Cerca de 15 segundos foram aguardados para realização do acesso remoto, onde nesse momento o script em **Bash** estaria terminando de instalar e configurar o software **Docker**. Neste momento através do software **OpenSSH**, o mesmo utilizado para acesso remoto, foram realizadas verificações dentro da maquina virtual da cloud para determinar se arquivos e pastas que deveriam ser enviadas já existiam nos seus respectivos locais do sistema de arquivos, caso esses arquivos não fossem encontrados, eram enviados para a maquina. Os arquivos transferidos foram: a pasta `.aws` contendo os arquivos `credentials` e `config` para configuração do usuário administrador `PedroheegerAdmin` no **AWS CLI** da maquina virtual, na maquina física isso já era configurado; a pasta `.docker` contendo o arquivo `config.json` que configura o acesso ao repositório do **Docker** (**Docker Hub**) através de um usuário; os arquivos `deployment1.yaml` e `deployment2.yaml` para execução de dois projetos, um projeto de teste do software **Kubernetes** e o projeto principal; e também o arquivo `Dockerfile` para construção da imagem do projeto principal.

Enquanto o script de criação era executado, o script **Bash** também era executado logo após a maquina virtual está instanciada. Este script foi dividido em etapas e todos os comandos e etapas executados precedem por um comando de `echo` para exibir a ação que foi realizada e em que parte do projeto isso estava. A execução desses comandos podem ser visualizadas através do arquivo `/var/log/cloud-init-output.log` dentro da maquina virtual. Todos os projetos preeliminares realizados foram executados em sequencial com o projeto principal, ou seja, a medida que o script estava em execução um projeto menor era realizado, em seguida ele era excluído e o próximo projeto era executado, sendo uma execução sequenciada e praticamente toda automatizada.

A primeira parte do script em **Bash** que rodou dentro da instância executou instalações básicas que já era padrão dos projetos que tenho criado em outros cursos ou bootcamps. Porém antes dessas intalações, o diretório corrente foi alterado para o diretório do usuário `/home/ubuntu`, sendo tudo instalado e baixado dentro deste diretório. Também foi feita uma atualização dos pacotes e do sistema e então os softwares básicos (**Nano** **Wget**, **Curl**, **Git**) foram instalado. Eles eram necessários para manipulação dentro do **Linux Ubuntu**. Também foi instalado o **ZShell**, um software de interface de linha de comando (CLI) que gosto de utilizar no **Linux**, ele foi definido como shell padrão da maquina instanciada e os três seguintes plugins dele foram baixados e configurados: **powerlevel10k**, **zsh-autosuggestions** e **zsh-syntax-highlighting**. O software de CLI da **AWS** também foi baixado, onde não foi necessário fazer o login do usuário, pois a pasta `.aws` com os arquivos enviados da maquina física se encarregaram de fazer essa configuração.

Na segunda etapa desse script foi feito o clone do repositório do projeto do **GitHub** fornecido pelo professor cujo nome da pasta do projeto foi `imersao-devops-cloud-02` e teve seu proprietário e grupo alterado de usuário `root` para o usuário `ubuntu`, usuário que realizava o acesso remoto. Em seguida foi feita a instalação do software **Docker** e a adição do usuário `ubuntu` ao grupo do **Docker** para executar os comandos sem a utilização do `sudo`. Antes de partir para etapa três, foi aguardado cerca de 100 segundos para esperar todos os cinco arquivos da maquina física serem transferidos para a instância na cloud.

A etapa 3 compreende extamente o desenvolvido na aula 1 deste curso, que foi um projeto preeliminar para aprendizagem do software **Docker**, cujo nome era `conversao-temperatura`. Ele foi inciado com o acesso a pasta deste projeto (`/home/ubuntu/imersao-devops-cloud-02/conversao-temperatura/src`) onde já existia um arquivo `Dockerfile` e os arquivos da aplicação clonados do repositório do **GitHub**. Nesta pasta foi elaborado um arquivo `.dockerignore` para ignorar a pasta do `node_modules` que era criada e então foi feito o build da imagem **Docker**. Essa imagem foi tagueda para as versões `v1` e `latest` sendo ambas enviadas para o **Docker Hub** (um repositório de imagens **Docker**) e podendo ser baixadas de qualquer lugar e por qualquer pessoa com acesso a internet e conta no **Docker Hub**. Por fim, foi executado o comando (`docker container run --name aplicacao1 -d -p 8080:8080 conversao-temperatura`) para criação do container da aplicação a partir dessa imagem construída pelo arquivo `Dockerfile` e realizando um bind de portas, ou seja, combinando a porta `8080` da maquina instanciada com a porta `8080` do container. Assim a aplicação pode ser acessada e executada através do número de IP público da maquina virtual concatenado com o número da porta `:8080`. 

A imagem 02 a seguir mostra a aplicação sendo acessada pelo navegador de internet da maquina física no IP da instância e na porta estabelecida. Agora fica explicado o porque foi nessário criar uma regra para a liberação da porta `8080` da maquina virtual da cloud. Após a imagem, o script do arquivo `Dockerfile` é exibido, observe que foi utilizado uma imagem base do **Node.js**, os arquivos `package` em formato **JSON** foram copiados e com a execução do comando `npm install`, as dependências nesses arquivos `package` eram criadas no sub-diretório `node_modules` que também era criado. Por fim, os demais arquivos da aplicação eram copiados, a aplicação ficava exposta na porta `8080` do container e o comando `node server.js` era acionado para execução da aplicação. Enquanto este container estivesse ativo, a aplicação estaria sendo executada no endereço estabelecido. A aplicação consistiu em um conversor de temperatura que convertia as temperaturas em Fahrenheit para Celsius e Celsius para Fahrenheit.

<div align="Center"><figure>
    <img src="./0-aux/img02.PNG" alt="img02"><br>
    <figcaption>Imagem 02.</figcaption>
</figure></div><br>

```dockerfile
FROM node:18.16.0
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 8080
CMD ["node", "server.js"]
```

kubectl create -f deployment.yaml
127
128
193
<a name="item02"><h4>Aula 2 - Kubernetes do zero ao deploy</h4></a>[Back to summary](#item0)

As próximas três etapas (4, 5 e 6) do arquivo de script em **Bash** são referentes a aula 2 deste curso. A etapa 4 consistiu na instalação do softwares **k3d** para execução de clusters **Kubernetes** e o **kubectl** que é um CLI para **Kubernetes**. Ao terminar de baixar o **kubectl** foi necessário alterar o proprietário e grupo da pasta `.kube` bem como do arquivo de configuração dentro desta pasta `.kube/config`. Cerca de 100 segundos foram aguardados antes de iniciar a etapa 5, neste momento o projeto 1 (`conversao-temperatura`) ainda estava no ar.

A etapa cinco iniciou com a remoção do container da aplicação do projeto 1 e então a pasta principal do projeto (`imersao-devops-cloud-02`) foi acessada. Neste diretório, um segundo projeto foi criado, assim como o primeiro foi um projeto preeliminar, agora para introduzir o software **Kubernetes**. Neste projeto foi criado um cluster com o comando `k3d cluster create meucluster1 -p "8080:30000@loadbalancer"` e em seguida executado o primeiro arquivo de manifesto **YAML** ([deployment1.yaml](./automation/resources/deployment1.yaml)) que foi enviado da maquina física para instância. O comando utilizado para execução foi o `kubectl apply -f deployment1.yaml`. Aproximadamente 100 segundos foram aguardados antes de realizar uma alteração na aplicação. No arquivo **YAML** `deployment1.yaml`, existia uma aplicação e um serviço, a imagem utilizada pelo container da aplicação era `fabricioveronez/web-page:blue` que era baixado do repositório do professor no **Docker Hub**. Porém, agora, essa imagem foi alterada para `fabricioveronez/web-page:green`. A diferença entre uma e outra era apenas a cor de fundo da aplicação. Então um novo deploy do arquivo **YAML** foi feito para a trocar da imagem do container da aplicação e cerca de 100 segundos foram aguardados com essa aplicação rodando. Por fim, a aplicação foi derrubada com o comando `kubectl delete -f deployment1.yaml` e o cluster removido com o comando `k3d cluster delete meucluster1`, finalizando o segundo projeto. As imagens 3 e 4 exibem a aplicação no ar através do navegador da web, sendo uma com a imagem cujo fundo da aplicação é azul e a outra com o fundo verde. Mais 45 segundos foram aguardados para concluir a remoção do cluster.

<div align="Center"><figure>
    <img src="./0-aux/img03.PNG" alt="img03"><br>
    <figcaption>Imagem 03.</figcaption>
</figure></div><br>

<div align="Center"><figure>
    <img src="./0-aux/img04.PNG" alt="img04"><br>
    <figcaption>Imagem 04.</figcaption>
</figure></div><br>

Na etapa 6 foi acessada a pasta do projeto principal `/home/ubuntu/imersao-devops-cloud-02/kube-news/src`, cujo nome do projeto era `kube-news`. Neste diretório, também foi criado um arquivo `.dockerignore`, ignorando a pasta `node_modules`, como visto anteriormente essa pasta é criada ao executar o comando `npm install`. Com o arquivo `Dockerfile` enviado da maquina física para a instância no sub-diretório `src`, o build da imagem foi realizado cujo nome ficou `pedroheeger/curso081_kube-news:v1`. Uma versão `latest` também foi tagueada a partir da versão `v1`. Ambas foram enviadas para um repositório no **Docker Hub**. Com a imagem criada, o cluster foi construído com o comando `k3d cluster create meucluster2 -p "8080:30000@loadbalancer"`.

O segundo arquivo de manifesto foi transferido da maquina física para a instância, criando uma sub-pasta `k8s` dentro do diretório do projeto principal `kube-news`. Alterando para esse sub-diretório, o comando de execução do manifesto foi realizado (`kubectl apply -f deployment2.yaml`). Nesse momento a aplicação já estava rodando na porta `8080`. Essa aplicação consistiu em um blog, porém este blog estava sem dados e para inserir dados no blog foi utilizado o arquivo [popula-dados.http](./automation/resources/popula-dados.http). Nele, foi alterado na URL `http://localhost:8080/api/post`, o `localhost` pelo IP da maquina da instância e com esse arquivo aberto no **Visual Studio Code (VS Code)**, utilizando a extensão **REST Client** foi clicado na opção `Send Request` para enviar uma requisição do tipo `POST` para endereço do blog onde os dados desse arquivo seriam inseridos como conteúdo do blog. Cerca de 150 segundos foram aguardados para garantir que o blog fosse populado com dados.

Agora, foi o momento de realizar a mudança de versão, ou seja, foi realizada uma alteração em no arquivo da aplicação (`/home/ubuntu/imersao-devops-cloud-02/kube-news/src/views/partial/header.ejs`), onde na linha 4 deste arquivo foi inserido `- v2` após o comando `<img class="logo" src="/img/kubenews-logo.svg" alt="Kubenews" srcset="" />`. A pasta corrente era a `k8s`, então foi necessário alterar para a pasta do arquivo `DockerFile` (`/home/ubuntu/imersao-devops-cloud-02/kube-news/src`) e fazer o build da imagem na versão `v2` e subi-lá para o **Docker Hub**. Voltando para a pasta `k8s`, foi feita uma alteração também no arquivo de manifesto **YAML** (`deployment2.yaml`), alterando a imagem do container da aplicação de `v1` para `v2`. As alterações foram aplicadas executando o arquivo de manifesto `kubectl apply -f deployment2.yaml`. Por fim, após cerca de 150 segundos a aplicação foi removida e o cluster excluído.

Na imagem 05 é exibido a aplicação sem a população de dados. Já nas imagens 06 e 07 é exibido a aplicação populada com dados nas versões `v1` e  `v2` respectivamente.

<div align="Center"><figure>
    <img src="./0-aux/img05.PNG" alt="img05"><br>
    <figcaption>Imagem 05.</figcaption>
</figure></div><br>

<div align="Center"><figure>
    <img src="./0-aux/img06.PNG" alt="img06"><br>
    <figcaption>Imagem 06.</figcaption>
</figure></div><br>

<div align="Center"><figure>
    <img src="./0-aux/img07.PNG" alt="img07"><br>
    <figcaption>Imagem 07.</figcaption>
</figure></div><br>




10250
6443


<a name="item03"><h4>Aula 3 - AWS: Potencialize sua aplicação com o poder da Cloud Computing</h4></a>[Back to summary](#item0)

Nesta aula, antes de continuar os scripts de automação, foi realizado a criação de uma conta na **AWS** e a criação de um usuário administrador anexando a ele a permissão `AdministratorAccess`, porém isto já estava feito. Em seguida, foi acessado com o usuário root da conta da **AWS** e pelo console foi configurado um alerta no serviço **AWS Budget** para que um email fosse enviado quando custo do serviços atingisse o valor determinado. Este processo teve que ser feito diretamente na conta do usuário root e pelo console, pois na **AWS CLI** instalada na maquina física, o usuário configurado é o usuário administrador `PedroheegerAdmin` que não tem permissões relacionadas a finanças.





curl -k https://35.175.237.145:42007


curl https://35.175.237.145:42007










<a name="item04"><h4>Aula 4 - Github Actions - Eficiência em entregas automatizadas</h4></a>[Back to summary](#item0)